# 集合

## List

### ArrayList
默认大小10，
使用无参构造；数组使用DEFAULTCAPACITY_EMPTY_ELEMENTDATA（空数组）；第一次插入数据的时候初始化数组，大小为10
初始化的时候传入大小，如果是不是0，初始化数组；如果是0，使用EMPTY_ELEMENTDATA（空数组），第一次插入的时候进行扩容，大小为1
### Vector
线程安全的List，内部逻辑和ArrayList基本相同，只是相关操作都使用synchronized修饰，效率较低
### LinkedList

双向链表

### CopyOnWriteArrayList
初始化大小是0，每次调用add都进行扩容，内部使用ReentrantLock保证线程安全
如果指定了下标进行add，下标不能超过原数组长度（即：只能新增在末尾或者插入在中间）

调用add，每次扩容+1

### Stack
继承Vector，先进后出

## Set
    A:存入集合的顺序和取出集合的顺序不一致
    B:没有索引
    C:存入集合的元素没有重复
### HashSet
底层是HashMap，使用key存储数据，value统一是常量PRESENT=new Object();因为key不会重复，所以存储的数据也没有重复的


### LinkedHashSet
继承HashSet；使用HashSet的构造方法，持有一个LinkedHashMap实例来完成链表操作
```
	HashSet(int initialCapacity, float loadFactor, boolean dummy) {
        map = new LinkedHashMap<>(initialCapacity, loadFactor);
    }
```
### TreeSet
```
implements NavigableSet<E>
NavigableSet<E> extends SortedSet<E>
```
TreeSet是有顺序的，可以自定义迭代器
存入的对象必须可以比较大小，实现Comparable接口

### EnumSet

### CopyOnWriteArraySet
底层采用CopyOnWriteArrayList实现；add调用CopyOnWriteArrayList的addIfAbsent方法（缺席时添加）；如果元素存在，就返回false；所以也不会插入重复元素
**内部CopyOnWriteArrayList是私有的，也没有提供以下标操作的方法**

## Map


### HashMap与Hashtable
#### HashMap
**hashMap的大小一定是2的幂次，如果传入的是不是2的幂次，会计算为大于等于这个数的最小的一个2次幂；**
初始化大小是16；负载因子0.75
##### 1.7和1.8比较

- 1.7底层是数组+链表；1.8数组+链表+红黑树，红黑树的节点类型是TreeNode
- 链表插入从头插法改为了尾插法
- 扩容的时候 1.7 需要对原数组中的元素进行重新 hash 定位在新数组的位置，1.8 采用更简单的判断逻辑，位置不变或索引+旧容量大小；
-  扩容时机改变，1.7先判断是偶需要扩容，在进行插入；1.8先进行插入，再进行扩容判断
##### 扩容
size大于threshold进行扩容```threshold = 数组长度*capacity（容量）```
##### 头插法有什么问题
扩容元素会重新进行hash，重新散列数据，扩容后链表的元素有可能还是在同一个链表中；
头插法并发的情况扩容的时候，复制链表过程中有可能在新数组上出现循环列表；这时候调用get获取这个位置的元素就会出现死循环

##### HashMap的hashCode怎么设计的
hashcode是32位int值，让高16位和低16位异或（扰动函数）；
- 降低hash碰撞，越分散越好
- 尽量高效，所以使用位运算
```
hashcode:
	h = hashscode(key);//原始hashcode
	h = h ^ (h>>>16);//高16位和低16位异或// 1.7采用了多次扰动
计算下标：(len - 1) & h;//计算下标，取数组长度位特征作为下标，相当于对（数组长度-1）取余
```
因为使用hashcode和数组长度&运算，所以下表只有数组长度的特征，使用hashcode高16位与低16位异或后，hashcode的低16位也带有了高位的特征，增加了随机性；


##### modCount问题
modCount是修改次数，迭代器中使用了这个变量判断遍历过程中map，如果不相同，就抛出异常ConcurrentModificationException
避免：使用iterator进行迭代修改；
	遍历过程中，避免其他线程修改map
##### 如果hashMap出现了不安全的问题，怎么解决
- 使用Hashtable 内部的方法使用synchronized修饰，效率较低
- 使用Collections工具进行synchronized包装，相当于在方法上加synchronized
- 使用ConcurrentHashMap

##### Java8 HashMap扩容时为什么不需要重新hash
原始获取位置的逻辑为（table-1）&e.hash
通过将数据的hash与扩容前的长度进行与操作，根据结果为0还是不为0来做对应的处理e.hash & oldCap
元素的hash和旧的数组长度进行&运算，0，表示位置没有变化，1表示位置变化，新位置为旧位置+oldCap
比如旧长度为8，这样就是7&e.hsah，相当于取低三位，扩容后长度变为16，相当于取低四位；而e.hash & oldCap相当于取新增位的状态，是0表示定位结果没有变化，1的话相当于定位增加了一个旧的长度
#### Hashtable
逻辑与HashMap相同，内部的方法使用synchronized修饰，**是线程安全的，但是效率比较低**
### LinkedHashMap
基于HashMap实现，Entry继承了HashMap的Node，新增了before和after，用于实现链表操作，这样LinkedHashMap就既具有了Map属性，也具有了链表属性，有顺序，也能快速查找
public LinkedHashMap(int initialCapacity,
                         float loadFactor,
                         boolean accessOrder)
accessOrder是用来设置链表的顺序是插入顺序还是访问顺序；true表示访问顺序，false表示插入顺序。

**通过实现HashMap的afterNodeAccess实现链表位置移动**
**扩展了afterNodeInsertion提供实现元素删除逻辑**

**如果是初始化是设定为访问顺序，get后会调用afterNodeAccess调整链表顺序**

**可以用来实现lru算法**（Least Recently Used：近期最少使用；选择最近最久未使用的数据进行淘汰 ）
### TreeMap

底层是红黑树

### ConcurrentHashMap
**不支持null的key或者value**
#### value为什么不能为null：
在ConcurrentMaps (ConcurrentHashMaps, ConcurrentSkipListMaps)这些考虑并发安全的容器中不允许null值的出现的主要原因是他可能会在并发的情况下带来难以容忍的二义性。而在非并发安全的容器中，这样的问题刚好是可以解决的。在map容器里面，调用map.get(key)方法得到的值是null，那你无法判断这个key是在map里面没有映射过，还是这个key在map里面根本就不存在。这种情况下，在非并发安全的map中，你可以通过map.contains(key)的方法来判断。但是在考虑并发安全的map中，在两次调用的过程中，这个值是有可能被改变的
#### key为什么不能为null：

#### 1.7
- Segment[] ; 分区，默认大小16，初始化完成后就不会改变了，Segment是一个内部类，继承了ReentrantLock，内部持有一个HashEntry[]
- HashEntry[]; 大小最小是2， 
- put：当执行put操作时，会进行第一次key的hash来定位Segment的位置，如果该Segment还没有初始化，即通过CAS操作进行赋值，然后进行第二次hash操作，找到相应的HashEntry的位置，这里会利用继承过来的锁的特性，在将数据插入指定的HashEntry位置时（链表的尾端），会通过继承ReentrantLock的tryLock（）方法尝试去获取锁，如果获取成功就直接插入相应的位置，如果已经有线程获取该Segment的锁，那当前线程会以自旋的方式去继续的调用tryLock（）方法去获取锁，超过指定次数就挂起，等待唤醒
- get：ConcurrentHashMap的get操作跟HashMap类似，只是ConcurrentHashMap第一次需要经过一次hash定位到Segment的位置，然后再hash定位到指定的HashEntry，遍历该HashEntry下的链表进行对比，成功就返回，不成功就返回null
- size：使用不加锁的模式去尝试多次计算ConcurrentHashMap的size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入，计算的结果是准确的；如果结果不一致，就会给每个Segment加上锁，然后计算ConcurrentHashMap的size返回
- 扩容：扩容不影响Segment，只对HashEntry进行扩容
#### 1.8
内部是table[] 元素是Node，红黑树的节点类型是TreeBin

- put的时候，获取数组位置上第一个元素，如何没有，使用CAS插入；
	- 如果有，锁住这个元素（synchronized）链表头节点或者树的根节点；然后进行插入逻辑；完成后，锁结束；
	- 判断是否达到树化的阈值，进行树化
		- 
- initTable；初始化，自旋{尝试CAS设置标记，设置成功，初始化Node数组，设置失败，线程让步，如果设置成功的线程一直得不到CPU资源，可能导致其他线程一直让步等待，CPU资源占用严重的情况出现}
- addCount ： **CELLSBUSY：counterCells修改锁；cellsBusy：counterCells元素属性修改锁**
``` 
使用BASECONUT和CountCell[]统计map大小
	- 对BASECOUNT进行+1（CAS），成功后，
	- 如果设置失败，获取当前线程的探针偏移量&CountCell[].len-1，
	- 获取CountCell数组中的 对象，如果是null，表示未被使用过，CAS设置这个CounterCell的value+1
	- 如果CountCell中对应位置是null或者竞争失败，进入fullAddCount
		- funnAddCount： 自旋
			- 数组不为空，获取对应位置的CountCell
				- CountCell为null，尝试竞争CELLBUSY占用数组，成功后，创建CounterCell进行计数，创建成功，退出，失败，生成新的线程指针hash（这样下次占用的数组位置可能会修改，避免竞争同一个位置），继续自旋
				- CountCell不是null，尝试CELLVALUE+1（CAS），成功继续，失败自旋
				- 如果再次竞争失败，查看counterCells是否被其他线程修改了引用（扩容）
				- 如果已经进行过扩容，修改hash，自旋；
				- 查看当前counterCells容量是否大于等于Runtime.getRuntime().availableProcessors()：硬件支持的真实并发线程数
				- 大于进行扩容，hash，自旋
			- 数组为空：竞争CELLSBUSY占用数组counterCells，竞争到，初始化数组，大小为2，放一个计数对象，计数为1
			- 如果竞争counterCells失败，尝试竞争一次BASECOUNT，成功+1，失败继续自旋
```
计数完成：
**是否扩容，逻辑目前不太懂**
```
如果是增加元素：自旋
- 判断元素个数是否大于阈值并且小于最大容量
	- sc = 当前阈值；n = 当前大小
	- 获取一个resizeStamp
	- 判断sc>0
		- sc大于0；.......
		- sc小于0；CAS修改sc（修改为负数）；成功进行扩容
```

- transfer扩容：

```
transferIndex = 数组长度
boolean advance = true;
boolean finishing = false; 是否有需要进行转移的元素
- 计算步长：stride 转移元素的单位
- 判断nextTable为null，创建新数组，扩容一倍；赋给nextTable
- 使用ForwardingNode对象占位转移的元素位置（如果有put进程进来，查看到要操作的位置上的对象是ForwardingNode对象，就帮助扩容线程进行元素转移）
	- 从尾部开始进行元素转移
	- CAS竞争TRANSFERINDEX；成功后计算出要转移位置的起始下标和下一次要转移的桶的位置（一个步长的位置）；竞争失败进行自旋
- 进行选择：
    - 判断
    - 判断目标节点元素是null的话，设置节点元素为ForwardingNode对象
    - 如果元素正在移动，进行下一个移动
    - 锁住要移动的元素，进行移动；移动完成后，设置节点元素为ForwardingNode对象

```

